{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle,os\n",
    "import os.path as osp\n",
    "import re\n",
    "from ohbm.api import Api\n",
    "import ohbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome, OHBM Trainer!\n"
     ]
    }
   ],
   "source": [
    "access_token=\"0C78129639B37234B95DBC94DA64F74A\"\n",
    "url='https://ww5.aievolution.com/hbm1701'\n",
    "api = Api(access_token,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import hashlib\n",
    "# BUF_SIZE is totally arbitrary, change for your app!\n",
    "BUF_SIZE = 65536  # lets read stuff in 64kb chunks!\n",
    "\n",
    "def get_hash(filename, hashfunc=hashlib.sha1()):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = None\n",
    "        while True:\n",
    "            data = f.read(BUF_SIZE)\n",
    "            if not data:\n",
    "                break\n",
    "            hashfunc.update(data)\n",
    "\n",
    "    return hashfunc.hexdigest()\n",
    "\n",
    "#def _get_hash():\n",
    "#    if hashtype == 'sha1': \n",
    "#        sha1 = hashlib.sha1()\n",
    "#    else \n",
    "#        md5 = hashlib.md5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hash_of_file(filepath,hashfunc='sha1'):\n",
    "    import hashlib\n",
    "    BUFSIZE = 2**10\n",
    "    if hashfunc == 'sha1':\n",
    "        hashf = hashlib.sha1()\n",
    "    with open(filepath, 'rb') as f:\n",
    "        while True:\n",
    "            block = f.read(BUFSIZE) # Magic number: one-megabyte blocks.\n",
    "            if not block: break\n",
    "            hashf.update(block)\n",
    "        return hashf.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pckg_dir = osp.dirname(osp.dirname(ohbm.__file__))\n",
    "data_dir = osp.join(pckg_dir, 'abstracts_data')\n",
    "abstract_pkl = osp.join(data_dir, 'abstracts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ABST_SHA1 = 'b5320edd9687a565938f5d2c0475720f0664882c'\n",
    "\n",
    "try:\n",
    "    abstracts=pickle.load(open(abstract_pkl,'rb'))\n",
    "    # assert hashlib.sha1(open(abstract_pkl).read()) == ABST_SHA1\n",
    "    assert (ABST_SHA1 == hash_of_file(abstract_pkl))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    abstracts = api.Abstracts.getAbstracts()\n",
    "    if not exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    pickle.dump(abstracts, open(osp.join(data_dir, 'abstracts.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_authors(author_str):\n",
    "    alist = [val for val in a['authors'].split('<sup>') if not val.endswith('</sup>')]\n",
    "    alist_clean = []\n",
    "    for val in alist:\n",
    "        newval = val\n",
    "        if '/sup' in val:\n",
    "            newval = val.split('/sup>, ')[1]\n",
    "        if '<u>' in val:\n",
    "            newval = val.split('>')[1].split('<')[0]\n",
    "        alist_clean.append(newval)\n",
    "    return alist_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@id',\n",
       " '@updatedon',\n",
       " '@insertedon',\n",
       " 'abstractNumber',\n",
       " 'submissionNumber',\n",
       " 'estimatedAttendance',\n",
       " 'estimatedCredits',\n",
       " 'approvedCredits',\n",
       " 'title',\n",
       " 'shortTitle',\n",
       " 'abstractType',\n",
       " 'embargoEndsOn',\n",
       " 'startsOn',\n",
       " 'endsOn',\n",
       " 'category',\n",
       " 'keywords',\n",
       " 'authors',\n",
       " 'institution',\n",
       " 'purpose',\n",
       " 'materialsMethods',\n",
       " 'results',\n",
       " 'conclusion',\n",
       " 'reference',\n",
       " 'latebreakingFlag',\n",
       " 'featuredFlag',\n",
       " 'acceptedFlag',\n",
       " 'completedFlag',\n",
       " 'status',\n",
       " 'previewurl',\n",
       " 'categories',\n",
       " 'speakers',\n",
       " 'documents',\n",
       " 'figures',\n",
       " 'events',\n",
       " 'planner']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(abstracts[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_new = []\n",
    "for a in abstracts:\n",
    "    a['authorslist'] = clean_authors(a['authors'])\n",
    "    #a['abstract'] = a['purpose'] + a['materialsMethods'] + a['results'] + a['conclusion']\n",
    "    abstracts_new.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(os.path.join(data_dir, 'ohbm2017_abstracts.json'), 'wt') as fp:\n",
    "    json.dump(abstracts_new, fp, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(['http://elastic:changeme@localhost:9200'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "url_base = 'http://localhost:9200/abstract/'\n",
    "for idx, d in enumerate(abstracts_new):\n",
    "    es.index(index='ohbm', doc_type='abstract', id=idx + 1, body=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
